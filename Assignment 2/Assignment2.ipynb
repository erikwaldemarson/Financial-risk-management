{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math as m\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "#from arch import arch_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              PL  VaRBHS      VaREWMA         VaRn         VaRt       VaRPot  \\\n",
      "Date                                                                           \n",
      "2005-01-01   190     NaN          NaN          NaN          NaN          NaN   \n",
      "2005-02-01   190     NaN          NaN          NaN          NaN          NaN   \n",
      "2005-03-01  -220     NaN          NaN          NaN          NaN          NaN   \n",
      "2005-05-01   120     NaN          NaN          NaN          NaN          NaN   \n",
      "2005-06-01   450     NaN          NaN          NaN          NaN          NaN   \n",
      "...          ...     ...          ...          ...          ...          ...   \n",
      "2008-12-25   500  3835.0  5685.328442  3099.600997  3894.837749  5533.676874   \n",
      "2008-12-26   300  3835.0  5651.307303  3099.176876  3885.509964  5533.676874   \n",
      "2008-12-28  -680  3835.0  5493.420633  3098.836653  3882.021708  5533.676874   \n",
      "2008-12-29 -1690  3835.0  5330.700046  3101.208561  3869.046817  5533.676874   \n",
      "2008-12-31   670  3835.0  5206.385930  3109.150064  3864.243575  5533.676874   \n",
      "\n",
      "                 ESEWMA          ESn          ESt        ESPot  Losses  \n",
      "Date                                                                    \n",
      "2005-01-01          NaN          NaN          NaN          NaN    -190  \n",
      "2005-02-01          NaN          NaN          NaN          NaN    -190  \n",
      "2005-03-01          NaN          NaN          NaN          NaN     220  \n",
      "2005-05-01          NaN          NaN          NaN          NaN    -120  \n",
      "2005-06-01          NaN          NaN          NaN          NaN    -450  \n",
      "...                 ...          ...          ...          ...     ...  \n",
      "2008-12-25  8983.182389  3544.596054  17316.95094  8245.104866    -500  \n",
      "2008-12-26  8935.710619  3544.247078  17051.92964  8245.104866    -300  \n",
      "2008-12-28  8740.921644  3543.935956  16969.91968  8245.104866     680  \n",
      "2008-12-29  8503.251624  3546.396997  16439.32808  8245.104866    1690  \n",
      "2008-12-31  8296.806927  3555.034995  15927.46627  8245.104866    -670  \n",
      "\n",
      "[1008 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "\n",
    "filename='DataLab2.csv'\n",
    "table = pd.read_csv(filename)\n",
    "table['Date'] = pd.to_datetime(table['Date'])\n",
    "table = table.set_index('Date')\n",
    "start = dt.datetime(2005, 1, 1)\n",
    "end = dt.datetime(2008,12,31)\n",
    "backtesting_sample = table[start:end]\n",
    "backtesting_sample['Losses'] = backtesting_sample['PL']*-1\n",
    "\n",
    "print(backtesting_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "#I choose start and end dates so that we have exactly M = 250 of the latest trading days in accordance with Basel\n",
    "start2007 = dt.datetime(2007, 4, 1) \n",
    "end2007 = dt.datetime(2007,12,31)\n",
    "\n",
    "start2008 = dt.datetime(2008, 4, 1)\n",
    "end2008 = dt.datetime(2008,12,31)\n",
    "\n",
    "sample_2007 = backtesting_sample[start2007:end2007]\n",
    "sample_2008 = backtesting_sample[start2008:end2008]\n",
    "\n",
    "print(len(sample_2007))\n",
    "print(len(sample_2008))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe storing pvalues Kupiec\n",
    "\n",
    "columns = ['VaRBHS', 'VaREWMA', 'VaRn', 'VaRt', 'VaRPot'] \n",
    "\n",
    "#Kupiec\n",
    "Kupiec_pval = pd.DataFrame()\n",
    "Kupiec = pd.DataFrame()\n",
    "\n",
    "#Traffic light\n",
    "Violations = pd.DataFrame()\n",
    "Traffic_light = pd.DataFrame()\n",
    "\n",
    "#Christoffersen\n",
    "Christoffersen_pval = pd.DataFrame()\n",
    "Christoffersen_frame = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Christoffersen(violations): #Used for christoffersen test\n",
    "    n1 = sum(violations)\n",
    "    n0 = len(violations) - n1\n",
    "\n",
    "    n11 = 0\n",
    "    n00 = 0\n",
    "    n01 = 0\n",
    "    n10 = 0\n",
    "\n",
    "    for r in range(0,len(violations)-1):\n",
    "        if violations[r]==1 and violations[r+1]==1:\n",
    "            n11 += 1\n",
    "        if violations[r]==0 and violations[r+1]==0:\n",
    "            n00 += 1\n",
    "        if violations[r]==0 and violations[r+1]==1:\n",
    "            n01 += 1\n",
    "        if violations[r]==1 and violations[r+1]==0:    \n",
    "            n10 += 1\n",
    "    # Empirical estimates of all needed probabilities\n",
    "    pi00 = n00 / (n00+n01) # Slide 8 VL 9\n",
    "    pi01 = n01 / (n00+n01)\n",
    "    pi10 = n10 / (n10+n11)\n",
    "    pi11 = n11 / (n10+n11)\n",
    "    pi0 = n0 / (n1+n0)\n",
    "    pi1 = n1 / (n1+n0)     \n",
    "\n",
    "\n",
    "    lnNull = np.log(pi0**n0*pi1**n1) # Slide 9 VL 9, second equation \n",
    "    lnAlt = np.log(pi00**n00*pi01**n01*pi10**n10*pi11**n11) # Slide 9 VL 9, first equation\n",
    "    LRind = -2*(lnNull-lnAlt)\n",
    "\n",
    "    # Pvalue for test stat that is chisquare(1) distributed (upper since right tail for one-sided test)\n",
    "    pVal = 1-stats.chi2.cdf(LRind,1) # 1 minus since right tail for one-sided test\n",
    "\n",
    "    return(pVal) #pVal for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "alpha = 0.99 #99% confidence level as with Basel\n",
    "M = 250 #according to Basel, we could of course set M = len(sample) in for loop below as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected nr. of violations = 0.01*250 = 2.5 \n",
      "\n",
      "number of violations \n",
      "\n",
      "      VaRBHS  VaREWMA  VaRn  VaRt  VaRPot\n",
      "2007      15        5    36    27       5\n",
      "2008       7        6    12     9       3\n",
      "\n",
      " \n",
      "P-values using Kupiec for each year and VaR \n",
      "\n",
      "            VaRBHS   VaREWMA      VaRn      VaRt    VaRPot\n",
      "2007  5.126074e-08  0.107812  0.000000  0.000000  0.107812\n",
      "2008  1.370145e-02  0.041183  0.000011  0.001057  0.456831\n",
      "\n",
      "Kupiec Test: If false then we have a bad VaR estimate (underestimating) and we reject H_0 \n",
      "\n",
      "      VaRBHS  VaREWMA   VaRn   VaRt  VaRPot\n",
      "2007   False     True  False  False    True\n",
      "2008    True     True  False  False    True\n",
      "\n",
      " \n",
      "P-values using Christoffersen for each year and VaR \n",
      "\n",
      "        VaRBHS   VaREWMA      VaRn      VaRt    VaRPot\n",
      "2007  0.256077  0.001622  0.019192  0.015718  0.620319\n",
      "2008  0.009151  0.004223  0.012301  0.030276  0.019575\n",
      "\n",
      "Christoffersen Test: If false then we have a bad VaR estimate  (underestimating) and we reject H_0 \n",
      "\n",
      "      VaRBHS  VaREWMA  VaRn  VaRt  VaRPot\n",
      "2007    True    False  True  True    True\n",
      "2008   False    False  True  True    True\n",
      "\n",
      " Traffic Light test \n",
      "\n",
      "     VaRBHS VaREWMA VaRn   VaRt VaRPot\n",
      "2007    Red   Amber  Red    Red  Amber\n",
      "2008  Amber   Amber  Red  Amber  Green\n"
     ]
    }
   ],
   "source": [
    "#Backtesting VaR\n",
    "\n",
    "\n",
    "for column in columns: #for each VaR measurement\n",
    "    #Temporary vectors for storing values in dataframes\n",
    "    Kup_pval = [] #Kupiec pvals\n",
    "    Kup_bool = [] #Kupiec reject or keep null hypothesis\n",
    "\n",
    "    Chris_pval = [] #Christoffersen pvals\n",
    "    Chris_bool = [] #Christoffersen reject or keep null hypothesis\n",
    "\n",
    "    zone = []  #traffic lights: green, amber or red\n",
    "    nrval_vec = [] #nr of violations vector\n",
    "\n",
    "    for sample in [sample_2007, sample_2008]:\n",
    "        violations = sample['Losses']>sample[column] # violations is when loss > VaR\n",
    "        violations = violations.astype(int) #convert to vector of 0s and 1s\n",
    "    \n",
    "\n",
    "        n_violations = sum(violations) #number of violations\n",
    "        nrval_vec.append(n_violations) #save in vec\n",
    "\n",
    "        #Kupiec test\n",
    "        pval_Kupiec = 1-stats.binom.cdf(n_violations-1,M,1-alpha) # Following slide 13 Video Lecture 8, one sided test\n",
    "        Kup_pval.append(pval_Kupiec)\n",
    "        Kup_bool.append(pval_Kupiec > 1-alpha)\n",
    "\n",
    "        #Christoffersen test\n",
    "        pval_Chris = Christoffersen(violations) #Function defined in cell above\n",
    "        Chris_pval.append(pval_Chris)\n",
    "        Chris_bool.append(pval_Chris > 1-alpha)\n",
    "\n",
    "        #Traffic light test\n",
    "        if n_violations >= 10:\n",
    "            zone.append('Red')\n",
    "        elif n_violations >= 5:\n",
    "            zone.append('Amber')\n",
    "        else:\n",
    "            zone.append('Green')\n",
    "            \n",
    "    #adding values to dataframes\n",
    "    Kupiec_pval[column] = Kup_pval\n",
    "    Kupiec[column] = Kup_bool\n",
    "\n",
    "    Christoffersen_pval[column] = Chris_pval\n",
    "    Christoffersen_frame[column] = Chris_bool\n",
    "\n",
    "    Violations[column] = nrval_vec\n",
    "    Traffic_light[column] = zone\n",
    "\n",
    "    #setting index to all dataframes\n",
    "    Kupiec_pval.index = ['2007', '2008']\n",
    "    Kupiec.index = ['2007', '2008']\n",
    "    Christoffersen_pval.index = ['2007', '2008']\n",
    "    Christoffersen_frame.index = ['2007', '2008']\n",
    "    Violations.index = ['2007', '2008']\n",
    "    Traffic_light.index = ['2007', '2008']\n",
    "\n",
    "print('Expected nr. of violations = 0.01*250 = 2.5 \\n')\n",
    "print('number of violations \\n')\n",
    "print(Violations)\n",
    "print('\\n \\n' +'P-values using Kupiec for each year and VaR \\n')\n",
    "print(Kupiec_pval)\n",
    "print('\\n' + 'Kupiec Test: If false then we have a bad VaR estimate (underestimating) and we reject H_0 \\n')\n",
    "print(Kupiec)\n",
    "print('\\n \\n' + 'P-values using Christoffersen for each year and VaR \\n')\n",
    "print(Christoffersen_pval)\n",
    "print('\\n' + 'Christoffersen Test: If false then we have a bad VaR estimate  (underestimating) and we reject H_0 \\n')\n",
    "print(Christoffersen_frame)\n",
    "print('\\n ' + 'Traffic Light test \\n')\n",
    "print(Traffic_light)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now create dataframes for backtesting ES\n",
    "ES_Z = pd.DataFrame()\n",
    "Backtest_ES = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-values backtesting ES for each year and VaR \n",
      "\n",
      "        ESEWMA        ESn       ESt     ESPot\n",
      "2007 -0.477792 -18.617657 -1.324354 -1.184306\n",
      "2008 -1.065068  -6.638042  0.103399 -0.514151\n",
      "\n",
      "If false then our ES estimate is bad and we reject the null hypothesis that it's a good estimate \n",
      "\n",
      "      ESEWMA    ESn    ESt  ESPot\n",
      "2007    True  False  False  False\n",
      "2008   False  False   True   True\n"
     ]
    }
   ],
   "source": [
    "VaR_list = ['VaREWMA', 'VaRn', 'VaRt', 'VaRPot']\n",
    "ES_list = ['ESEWMA', 'ESn', 'ESt', 'ESPot']\n",
    "\n",
    "for i in range(len(VaR_list)): #Same as for VaR but now for backtesting ES\n",
    "    #Temporary vectors\n",
    "    Z_vec = [] #z-values \n",
    "    bool_vec = [] #reject or keep H_0\n",
    "\n",
    "    for sample in [sample_2007, sample_2008]:\n",
    "        violations = sample['Losses']>sample[VaR_list[i]] \n",
    "        violations = violations.astype(int)\n",
    "\n",
    "        #Z-score according to Acerbi-Szekely (2015)\n",
    "        Z = -M**-1*sum((violations*sample['Losses']/(1-alpha))/sample[ES_list[i]]) + 1\n",
    "\n",
    "        Z_vec.append(Z) #store z-val\n",
    "        bool_vec.append(Z > -0.82) #assuming t-dist with dgf = 3, mean = 0 and sigma = 1, see L10 slide 11\n",
    "\n",
    "       \n",
    "    ES_Z[ES_list[i]] = Z_vec\n",
    "    Backtest_ES[ES_list[i]] = bool_vec\n",
    "\n",
    "    ES_Z.index = ['2007', '2008']\n",
    "    Backtest_ES.index = ['2007', '2008']\n",
    "\n",
    "        \n",
    "print('Z-values backtesting ES for each year and VaR \\n')\n",
    "print(ES_Z)\n",
    "print('\\n' + 'If false then our ES estimate is bad and we reject the null hypothesis that it\\'s a good estimate \\n')\n",
    "print(Backtest_ES)\n",
    "\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) There is a lot of variation depending on the year for the different estimates. Understandable since 2008 was a hectic year. For VaR estimates they are consistent in each individual test except for VaRBHS but they typically differ between test. The only VaR estimate that is consistent for both years and Christoffersen and Kupiec is VaRPOT.\n",
    "\n",
    "No ES method is consistent for both 2007 and 2008."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) For VaR I would pick VaRPOT since it passes both Christoffersen and Kupiec test. In Traffic light test it is Amber / Green.\n",
    "\n",
    "ES is a bit more tricky, as there doesn't seem to be a perfect method. I would probably pick either ESEWMA or ESPoT since they have the highest Z-values. For consistency sake I would choose ESPoT since it fits nicely with VaRPOT but I don't think there is a perfect answer in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
